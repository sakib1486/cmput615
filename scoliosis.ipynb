{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scoliosis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml==5.1"
      ],
      "metadata": {
        "id": "0FFWmCyBOVrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)"
      ],
      "metadata": {
        "id": "MJ2Hqaw5OavM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html"
      ],
      "metadata": {
        "id": "C67q8p_TOc3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
        "\n",
        "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "#Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "from detectron2.structures import BoxMode"
      ],
      "metadata": {
        "id": "skz4fp1qOlsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_dicts(directory, classes):\n",
        "    dataset_dicts = []\n",
        "    for filename in [file for file in os.listdir(directory) if file.endswith('.json')]:\n",
        "        json_file = os.path.join(directory, filename)\n",
        "        with open(json_file) as f:\n",
        "            img_anns = json.load(f)\n",
        "\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(directory, img_anns[\"imagePath\"])\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        #record[\"height\"] =3000\n",
        "        #record[\"width\"] = 2000\n",
        "      \n",
        "        annos = img_anns[\"shapes\"]\n",
        "        objs = []\n",
        "        for anno in annos:\n",
        "            px = [a[0] for a in anno['points']] # x coord\n",
        "            py = [a[1] for a in anno['points']] # y-coord\n",
        "            poly = [(x, y) for x, y in zip(px, py)] # poly for segmentation\n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": classes.index(anno['label']),\n",
        "                \"iscrowd\": 0\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts"
      ],
      "metadata": {
        "id": "6Jza3axqOq6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['rod']\n",
        "\n",
        "\n",
        "#File Path needs to be chnged according to the firectory where it is saved\n",
        "data_path = '/content/drive/MyDrive/abc/abc/scoliosis 2000 3000/'\n",
        "\n",
        "for d in [\"train\", \"test24\"]:\n",
        "    DatasetCatalog.register(\n",
        "        \"category_\" + d, \n",
        "        lambda d=d: get_data_dicts(data_path+d, classes)\n",
        "    )\n",
        "    MetadataCatalog.get(\"category_\" + d).set(thing_classes=classes)\n",
        "\n",
        "microcontroller_metadata = MetadataCatalog.get(\"category_train\")"
      ],
      "metadata": {
        "id": "f9VjOfVKOs9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import ColorMode, Visualizer"
      ],
      "metadata": {
        "id": "KpV9mIkfO3m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"category_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 200\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=True)\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "B7qGNvFuPNeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 \n",
        "cfg.DATASETS.TEST = (\"rod_detection\", )\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "test_dataset_dicts = get_data_dicts(data_path+'test24', classes)\n",
        "\n",
        "outputs = list()\n",
        "images = list()\n",
        "for d in test_dataset_dicts:    \n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    images.append(img)\n",
        "    o = predictor(img)\n",
        "    v = Visualizer(img[:, :, ::-1],\n",
        "                   metadata=microcontroller_metadata, \n",
        "                   scale=0.5, \n",
        "                   instance_mode=ColorMode.IMAGE_BW # removes the colors of unsegmented pixels\n",
        "    )\n",
        "    outputs.append(o)\n",
        "    v = v.draw_instance_predictions(o[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize = (28,20))\n",
        "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9Pa3PyS6PVAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onSVaFGAMv6R"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from PIL import Image\n",
        "import PIL\n",
        "for i, obj in enumerate(outputs): ### [(0, p1]), (1, p2)]\n",
        "  masks = np.asarray(obj['instances'].pred_masks.to(\"cpu\"))\n",
        "  item_mask = masks[0]\n",
        "  # Get the true bounding box of the mask (not the same as the bbox prediction)\n",
        "  segmentation = np.where(item_mask == True)\n",
        "  x_min = int(np.min(segmentation[1]))\n",
        "  x_max = int(np.max(segmentation[1]))\n",
        "  y_min = int(np.min(segmentation[0]))\n",
        "  y_max = int(np.max(segmentation[0]))\n",
        "  print(x_min, x_max, y_min, y_max)\n",
        "\n",
        "  # Create a cropped image from just the portion of the image we want\n",
        "  cropped = Image.fromarray(images[i][y_min:y_max, x_min:x_max, :], mode='RGB')\n",
        "  cropped.save(\"/content/output/\"+str(i+1)+\".jpg\")\n",
        "\n",
        "  plt.figure(figsize = (12,8))\n",
        "  plt.imshow(cropped)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"from PIL import Image\n",
        "\n",
        "# Get the masks\n",
        "masks = np.asarray(outputs[\"instances\"].pred_masks.to(\"cpu\"))\n",
        "\n",
        "# Pick an item to mask\n",
        "item_mask = masks[0]\n",
        "\n",
        "# Get the true bounding box of the mask (not the same as the bbox prediction)\n",
        "segmentation = np.where(item_mask == True)\n",
        "x_min = int(np.min(segmentation[1]))\n",
        "x_max = int(np.max(segmentation[1]))\n",
        "y_min = int(np.min(segmentation[0]))\n",
        "y_max = int(np.max(segmentation[0]))\n",
        "print(x_min, x_max, y_min, y_max)\n",
        "\n",
        "# Create a cropped image from just the portion of the image we want\n",
        "cropped = Image.fromarray(img[y_min:y_max, x_min:x_max, :], mode='RGB')\n",
        "plt.imshow(cropped)\n",
        "\n",
        "#J = cv2.imwrite('/content/drive/MyDrive/abc/poly/'+ '.jpg',cropped)\n",
        "\n",
        "# Create a PIL image out of the mask\n",
        "mask = Image.fromarray((item_mask * 255).astype('uint8'))\n",
        "#plt.imshow(mask)\n",
        "\n",
        "\n",
        "# Crop the mask to match the cropped image\n",
        "cropped_mask = mask.crop((x_min, y_min, x_max, y_max))\n",
        "#plt.imshow(cropped_mask)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "lightgrayimage = 200 * np.ones(shape=[512, 512, 3], dtype=np.uint8)\n",
        "cv2_imshow(lightgrayimage)\n",
        "\n",
        "# Load in a background image and choose a paste position\n",
        "background = Image.fromarray(img, mode='RGB')\n",
        "paste_position = (1000,1500)\n",
        "\n",
        "# Create a new foreground image as large as the composite and paste the cropped image on top\n",
        "new_fg_image = Image.new('RGB', background.size)\n",
        "new_fg_image.paste(cropped, paste_position)\n",
        "\n",
        "# Create a new alpha mask as large as the composite and paste the cropped mask\n",
        "new_alpha_mask = Image.new('L', background.size, color = 0)\n",
        "new_alpha_mask.paste(cropped_mask, paste_position)\n",
        "\n",
        "# Compose the foreground and background using the alpha mask\n",
        "composite = Image.composite(new_fg_image, background, new_alpha_mask)\n",
        "\n",
        "# Display the image\n",
        "cv2_imshow(np.array(composite))\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "A4l3bdHRPf_r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}